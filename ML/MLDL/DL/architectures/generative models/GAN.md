GAN (Generative Adversarial Network) - генеративно состязательная сеть - это генеративная модель, которая генерирует новые примеры из распределения обучающей выборки.

Впервые представлена в оригинальной статье [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) Ian. J. Goodfellow в 2014 году. 

Состоит из двух частей:

1. Генератор - учится генерировать правдоподобные данные, которые становятся обучающей выборкой для дискриминатора.
2. Дискриминатор - учится отличать фальшивые данные генератора от реальных, наказывает генератор за получение неправдоподобных результатов.

## Дискриминатор

В архитектуре GAN дискриминатор выполняет роль "критика", который учится отличать настоящие данные от фейков, сгенерированных генератором. Дискриминатор - это простой классификатор, архитектура классификатора может быть любая.

Классификатор дискриминатора принимает два входа:
- Fake data - positive examples
- Real data - negative examples

Пока обучается дискриминатор веса генератора заморожены.

**Обучение дискриминатора**

Дискриминатор порождает две функции потерь: для себя и генератора, но обучается только на своей.

**Процесс обучения:**
1. Дискриминатор классифицирует реальные данные и фейковые, полученные от генератора.
2. Функция потерь дискриминатора штрафует дискриминатор за ошибочные предсказания.
3. Обновляются веса дискриминатора через обратное распространение ошибки.

## Генератор

Генератор учится генерировать фейковые данные, используя обратную связь от дискриминатора, чтобы дискриминатор помечал их как реальные.

Пока обучается генератор веса дискриминатора заморожены.

**Обучение генератора**

1. Генерируются случайный шум. В классической реализации GAN распределение случайного шума неважно, обычно используется нормальное.
2. Генератор трансформирует шум в данные.
3. Дискриминатор классифицирует данные.
4. Получаем значение функции потерь для генератора.
5. Распространяем ошибку назад через дискриминатор к генератору.
6. Используем градиенты для обновления весов генератора, при этом веса дискриминатора остаются неизменными.

## Общая схема обучения

1. Дискриминатор обучается одну или несколько эпох.
2. Генератор обучается одну или несколько эпох.
3. Повторяем шаги 1 и 2 для обучения сети.

Показатель хорошо обученной сети - точность дискриминатора около 50% (случайное угадывание).

## Сходимость сети

**Проблема сходимости сети GAN** 
Обратная связь дискриминатора со временем становится все менее значимой, так как при хорошо обученном генераторе дискриминатор начинает угадывать. В таком случае начинает страдать и качество генератора тоже, так как он начинает ориентироваться на мусорную обратную связь.

## Функция потерь

В общем случае сеть GAN старается воспроизвести распределение тренировочного датасета. Для этого нужна функция потерь, которая бы отражала расстояние между распределением полученным GAN и настоящим распределением.

### Minimax Loss

В оригинальной статье представлена эта функция потерь:
$E_x[log(D(x))]+E_z[log(1-D(G(z)))]$ где
$D(x)$  - вероятность того, что настоящий элемент $x$ настоящий
$E_x$ - ожидаемое значение для всех реальных экземпляров данных
$G(z)$ - выход генератора при случайном шуме $z$
$D(G(z))$ - вероятность того, что фейковый $G(z)$ настоящий
$E_z$ - ожидаемое значение по всем случайным входам в генератор

